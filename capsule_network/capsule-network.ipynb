{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# import resources\nimport numpy as np\nimport torch\n\nfrom torchvision import datasets\nimport torchvision.transforms as transforms\n\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nimport torch.optim as optim\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# random seed (for reproducibility)\nseed = 1\n\n# set random seed for numpy\nnp.random.seed(seed)\n\n# set random seed for pytorch\ntorch.manual_seed(seed)","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"<torch._C.Generator at 0x7fa871de5eb0>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# number of subprocesses to use for data loading\nnum_workers = 0\n\n# how many samples per batch to load\nbatch_size = 20\n\n# convert data to Tensors\ntransform = transforms.ToTensor()\n\n# choose the training and test datasets\ntrain_data = datasets.MNIST(\n    root='data', \n    train=True, \n    download=True, \n    transform=transform\n)\n\ntest_data = datasets.MNIST(\n    root='data', \n    train=False, \n    download=True, \n    transform=transform\n)\n\n# prepare data loaders\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers)\n\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=num_workers)","execution_count":4,"outputs":[{"output_type":"stream","text":"Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85e75efbaa85483185e9e7e9440881aa"}},"metadata":{}},{"output_type":"stream","text":"Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05c4a4edd67c41c68e7380a5ec6ff264"}},"metadata":{}},{"output_type":"stream","text":"Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afb1703ddf5b423caa79884d940add10"}},"metadata":{}},{"output_type":"stream","text":"Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f621902b913e44d3b4361f79a23c0e81"}},"metadata":{}},{"output_type":"stream","text":"Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\nProcessing...\nDone!\n\n\n\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/conda-bld/pytorch_1591914880026/work/torch/csrc/utils/tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# obtain one batch of training images\n\ndataiter = iter(train_loader)\nimages, labels = dataiter.next()\nimages = images.numpy()\n\n# plot the images in the batch, along with the corresponding labels\n\nfig = plt.figure(figsize=(25, 4))\n\nfor idx in np.arange(batch_size):\n    \n    ax = fig.add_subplot(2, batch_size/2, idx+1, xticks=[], yticks=[])\n    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n    # print out the correct label for each image\n    # .item() gets the value contained in a Tensor\n    ax.set_title(str(labels[idx].item()))","execution_count":5,"outputs":[{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1800x288 with 20 Axes>","image/png":"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\n"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ConvLayer(nn.Module):\n    \n    def __init__(self, in_channels=1, out_channels=256):\n        \n        \"\"\"\n        Constructs the ConvLayer with a specified input and output size.\n        \n        in_channels: input depth of an image, default value = 1\n        out_channels: output depth of the convolutional layer, default value = 256\n        \"\"\"\n        \n        super(ConvLayer, self).__init__()\n\n        # defining a convolutional layer of the specified size\n        \n        self.conv = nn.Conv2d(\n            in_channels, \n            out_channels, \n            kernel_size=9, \n            stride=1, \n            padding=0\n        )\n\n    def forward(self, x):\n        \n        \"\"\"\n        Defines the feedforward behavior.\n        \n        x: the input to the layer; an input image\n        return: a relu-activated, convolutional layer \n        \"\"\"\n        \n        # applying a ReLu activation to the outputs of the conv layer\n        features = F.relu(self.conv(x)) # will have dimensions (batch_size, 20, 20, 256)\n        \n        return features","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class PrimaryCaps(nn.Module):\n    \n    def __init__(self, num_capsules=8, in_channels=256, out_channels=32):\n        \n        \"\"\"\n        Constructs a list of convolutional layers to be used in creating capsule output vectors.\n        \n        num_capsules: number of capsules to create\n        in_channels: input depth of features, default value = 256\n        out_channels: output depth of the convolutional layers, default value = 32\n        \"\"\"\n        \n        super(PrimaryCaps, self).__init__()\n\n        # creating a list of convolutional layers for each capsule I want to create\n        # all capsules have a conv layer with the same parameters\n        self.capsules = nn.ModuleList(\n            [\n                nn.Conv2d(\n                    in_channels=in_channels, \n                    out_channels=out_channels, \n                    kernel_size=9, \n                    stride=2, \n                    padding=0) \n                for _ in range(num_capsules)\n            ]\n        )\n    \n    def forward(self, x):\n        \n        \"\"\"\n        Defines the feedforward behavior.\n        \n        x: the input; features from a convolutional layer\n        return: a set of normalized, capsule output vectors\n        \"\"\"\n        \n        # get batch size of inputs\n        batch_size = x.size(0)\n        \n        # reshape convolutional layer outputs to be (batch_size, vector_dim=1152, 1)\n        u = [ capsule(x).view(batch_size, 32 * 6 * 6, 1) for capsule in self.capsules ]\n        \n        # stack up output vectors, u, one for each capsule\n        u = torch.cat(u, dim=-1)\n        \n        # squashing the stack of vectors\n        u_squash = self.squash(u)\n        \n        return u_squash\n    \n    def squash(self, input_tensor):\n        \n        \"\"\"\n        Squashes an input Tensor so it has a magnitude between 0-1.\n        \n        input_tensor: a stack of capsule inputs, s_j\n        return: a stack of normalized, capsule output vectors, v_j\n        \"\"\"\n        \n        squared_norm = (input_tensor ** 2).sum(dim=-1, keepdim=True)\n        scale = squared_norm / (1 + squared_norm) # normalization coeff\n        output_tensor = scale * input_tensor / torch.sqrt(squared_norm)\n        \n        return output_tensor","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def softmax(input_tensor, dim=1):\n    \n    # transpose input\n    transposed_input = input_tensor.transpose(dim, len(input_tensor.size()) - 1)\n    \n    # calculate softmax\n    softmaxed_output = F.softmax(transposed_input.contiguous().view(-1, transposed_input.size(-1)), dim=-1)\n    \n    # un-transpose result\n    return softmaxed_output.view(*transposed_input.size()).transpose(dim, len(input_tensor.size()) - 1)","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dynamic routing\ndef dynamic_routing(b_ij, u_hat, squash, routing_iterations=3):\n    \n    \"\"\"\n    Performs dynamic routing between two capsule layers.\n    \n    b_ij: initial log probabilities that capsule i should be coupled to capsule j\n    u_hat: input, weighted capsule vectors, W u\n    squash: given, normalizing squash function\n    routing_iterations: number of times to update coupling coefficients\n    return: v_j, output capsule vectors\n    \"\"\"\n    \n    # update b_ij, c_ij for number of routing iterations\n    for iteration in range(routing_iterations):\n        \n        # softmax calculation of coupling coefficients, c_ij\n        c_ij = softmax(b_ij, dim=2)\n\n        # calculating total capsule inputs, s_j = sum(c_ij*u_hat)\n        s_j = (c_ij * u_hat).sum(dim=2, keepdim=True)\n\n        # squashing to get a normalized vector output, v_j\n        v_j = squash(s_j)\n\n        # if not on the last iteration, calculate agreement and new b_ij\n        if iteration < routing_iterations - 1:\n            \n            # agreement\n            a_ij = (u_hat * v_j).sum(dim=-1, keepdim=True)\n            \n            # new b_ij\n            b_ij = b_ij + a_ij\n    \n    return v_j # return latest v_j","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DigitCaps(nn.Module):\n    \n    def __init__(self, num_capsules=10, previous_layer_nodes=32*6*6, in_channels=8, out_channels=16):\n        \n        \"\"\"\n        Constructs an initial weight matrix, W, and sets class variables.\n        \n        num_capsules: number of capsules to create\n        previous_layer_nodes: dimension of input capsule vector, default value = 1152\n        in_channels: number of capsules in previous layer, default value = 8\n        out_channels: dimensions of output capsule vector, default value = 16\n        \"\"\"\n        \n        super(DigitCaps, self).__init__()\n\n        # setting class variables\n        self.num_capsules = num_capsules\n        self.previous_layer_nodes = previous_layer_nodes # vector input (dim=1152)\n        self.in_channels = in_channels # previous layer's number of capsules\n\n        # starting out with a randomly initialized weight matrix, W\n        # these will be the weights connecting the PrimaryCaps and DigitCaps layers\n        self.W = nn.Parameter(\n            torch.randn(\n                num_capsules, \n                previous_layer_nodes, \n                in_channels, out_channels\n            )\n        )\n\n    def forward(self, u):\n        \n        \"\"\"\n        Defines the feedforward behavior.\n        \n        u: the input; vectors from the previous PrimaryCaps layer\n        return: a set of normalized, capsule output vectors\n        \"\"\"\n        \n        # adding batch_size dims and stacking all u vectors\n        u = u[None, :, :, None, :]\n        \n        # 4D weight matrix\n        W = self.W[:, None, :, :, :]\n        \n        # calculating u_hat = W*u\n        u_hat = torch.matmul(u, W)\n\n        # getting the correct size of b_ij\n        # setting them all to 0, initially\n        b_ij = torch.zeros(*u_hat.size())\n        \n        # moving b_ij to GPU, if available\n        b_ij = b_ij.to(device)\n\n        # update coupling coefficients and calculate v_j\n        v_j = dynamic_routing(b_ij, u_hat, self.squash, routing_iterations=3)\n\n        return v_j # return final vector outputs\n    \n    \n    def squash(self, input_tensor):\n        \n        \"\"\"\n        Squashes an input Tensor so it has a magnitude between 0-1.\n        \n        input_tensor: a stack of capsule inputs, s_j\n        return: a stack of normalized, capsule output vectors, v_j\n        \"\"\"\n        \n        # same squash function as before\n        squared_norm = (input_tensor ** 2).sum(dim=-1, keepdim=True)\n        scale = squared_norm / (1 + squared_norm) # normalization coeff\n        output_tensor = scale * input_tensor / torch.sqrt(squared_norm)\n        \n        return output_tensor","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Decoder(nn.Module):\n    \n    def __init__(self, input_vector_length=16, input_capsules=10, hidden_dim=512):\n        \n        \"\"\"\n        Constructs an series of linear layers + activations.\n        \n        input_vector_length: dimension of input capsule vector, default value = 16\n        input_capsules: number of capsules in previous layer, default value = 10\n        hidden_dim: dimensions of hidden layers, default value = 512\n        \"\"\"\n        \n        super(Decoder, self).__init__()\n        \n        # calculate input_dim\n        input_dim = input_vector_length * input_capsules\n        \n        # define linear layers + activations\n        self.linear_layers = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim), # first hidden layer\n            nn.ReLU(inplace=True),\n            nn.Linear(hidden_dim, hidden_dim*2), # second, twice as deep\n            nn.ReLU(inplace=True),\n            nn.Linear(hidden_dim*2, 28*28), # can be reshaped into 28*28 image\n            nn.Sigmoid() # sigmoid activation to get output pixel values in a range from 0-1\n        )\n        \n    def forward(self, x):\n        \n        \"\"\"\n        Defines the feedforward behavior.\n        \n        x: the input; vectors from the previous DigitCaps layer\n        return: two things, reconstructed images and the class scores, y\n        \"\"\"\n        \n        classes = (x ** 2).sum(dim=-1) ** 0.5\n        classes = F.softmax(classes, dim=-1)\n        \n        # find the capsule with the maximum vector length\n        # here, vector length indicates the probability of a class' existence\n        _, max_length_indices = classes.max(dim=1)\n        \n        # create a sparse class matrix\n        sparse_matrix = torch.eye(10) # 10 is the number of classes\n        sparse_matrix = sparse_matrix.to(device)\n        \n        # get the class scores from the \"correct\" capsule\n        y = sparse_matrix.index_select(dim=0, index=max_length_indices.data)\n        \n        # create reconstructed pixels\n        x = x * y[:, :, None]\n        \n        # flatten image into a vector shape (batch_size, vector_dim)\n        flattened_x = x.contiguous().view(x.size(0), -1)\n        \n        # create reconstructed image vectors\n        reconstructions = self.linear_layers(flattened_x)\n        \n        # return reconstructions and the class scores, y\n        return reconstructions, y","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CapsuleNetwork(nn.Module):\n    \n    def __init__(self):\n        \n        \"\"\"\n        Constructs a complete Capsule Network.\n        \"\"\"\n        \n        super(CapsuleNetwork, self).__init__()\n        \n        self.conv_layer = ConvLayer()\n        self.primary_capsules = PrimaryCaps()\n        self.digit_capsules = DigitCaps()\n        self.decoder = Decoder()\n                \n    def forward(self, images):\n        \n        \"\"\"\n        Defines the feedforward behavior.\n        \n        images: the original MNIST image input data\n        return: output of DigitCaps layer, reconstructed images, class scores\n        \"\"\"\n        \n        primary_caps_output = self.primary_capsules(self.conv_layer(images))\n        caps_output = self.digit_capsules(primary_caps_output).squeeze().transpose(0,1)\n        reconstructions, y = self.decoder(caps_output)\n        \n        return caps_output, reconstructions, y","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# instantiate and print net\ncapsule_net = CapsuleNetwork()\n\nprint(device)\ncapsule_net.to(device)","execution_count":13,"outputs":[{"output_type":"stream","text":"cuda\n","name":"stdout"},{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"CapsuleNetwork(\n  (conv_layer): ConvLayer(\n    (conv): Conv2d(1, 256, kernel_size=(9, 9), stride=(1, 1))\n  )\n  (primary_capsules): PrimaryCaps(\n    (capsules): ModuleList(\n      (0): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n      (1): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n      (2): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n      (3): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n      (4): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n      (5): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n      (6): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n      (7): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n    )\n  )\n  (digit_capsules): DigitCaps()\n  (decoder): Decoder(\n    (linear_layers): Sequential(\n      (0): Linear(in_features=160, out_features=512, bias=True)\n      (1): ReLU(inplace=True)\n      (2): Linear(in_features=512, out_features=1024, bias=True)\n      (3): ReLU(inplace=True)\n      (4): Linear(in_features=1024, out_features=784, bias=True)\n      (5): Sigmoid()\n    )\n  )\n)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CapsuleLoss(nn.Module):\n    \n    def __init__(self):\n        \n        \"\"\"\n        Constructs a CapsuleLoss module.\n        \"\"\"\n        \n        super(CapsuleLoss, self).__init__()\n        \n        self.reconstruction_loss = nn.MSELoss(reduction='sum') # cumulative loss, equiv to size_average=False\n\n    def forward(self, x, labels, images, reconstructions):\n        \n        \"\"\"\n        Defines how the loss compares inputs.\n        x: digit capsule outputs\n        labels: \n        images: the original MNIST image input data\n        reconstructions: reconstructed MNIST image data\n        return: weighted margin and reconstruction loss, averaged over a batch\n        \"\"\"\n        \n        batch_size = x.size(0)\n\n        ##  calculate the margin loss   ##\n        \n        # get magnitude of digit capsule vectors, v_c\n        v_c = torch.sqrt((x**2).sum(dim=2, keepdim=True))\n\n        # calculate \"correct\" and incorrect loss\n        left = F.relu(0.9 - v_c).view(batch_size, -1)\n        right = F.relu(v_c - 0.1).view(batch_size, -1)\n        \n        # sum the losses, with a lambda = 0.5\n        margin_loss = labels * left + 0.5 * (1. - labels) * right\n        margin_loss = margin_loss.sum()\n\n        ##  calculate the reconstruction loss   ##\n        images = images.view(reconstructions.size()[0], -1)\n        reconstruction_loss = self.reconstruction_loss(reconstructions, images)\n\n        # return a weighted, summed loss, averaged over a batch size\n        return (margin_loss + 0.0005 * reconstruction_loss) / images.size(0)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# custom loss\ncriterion = CapsuleLoss()\n\n# Adam optimizer with default params\noptimizer = optim.Adam(capsule_net.parameters())","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(capsule_net, criterion, optimizer, n_epochs, print_every=300):\n    \n    \"\"\"\n    Trains a capsule network and prints out training batch loss statistics.\n    Saves model parameters if *validation* loss has decreased.\n    \n    capsule_net: trained capsule network\n    criterion: capsule loss function\n    optimizer: optimizer for updating network weights\n    n_epochs: number of epochs to train for\n    print_every: batches to print and save training loss, default = 100\n    return: list of recorded training losses\n    \"\"\"\n\n    # track training loss over time\n    losses = []\n\n    # one epoch = one pass over all training data \n    for epoch in range(1, n_epochs+1):\n\n        # initialize training loss\n        train_loss = 0.0\n        \n        capsule_net.train() # set to train mode\n    \n        # get batches of training image data and targets\n        for batch_i, (images, target) in enumerate(train_loader):\n\n            # reshape and get target class\n            target = torch.eye(10).index_select(dim=0, index=target)\n\n            images, target = images.to(device), target.to(device)\n\n            # zero out gradients\n            optimizer.zero_grad()\n            \n            # get model outputs\n            caps_output, reconstructions, y = capsule_net(images)\n            \n            # calculate loss\n            loss = criterion(caps_output, target, images, reconstructions)\n            \n            # perform backpropagation and optimization\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item() # accumulated training loss\n            \n            # print and record training stats\n            if batch_i != 0 and batch_i % print_every == 0:\n                \n                avg_train_loss = train_loss/print_every\n                losses.append(avg_train_loss)\n                \n                print('Epoch: {} \\tTraining Loss: {:.8f}'.format(epoch, avg_train_loss))\n                train_loss = 0 # reset accumulated training loss\n        \n    return losses","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# training for 3 epochs\nn_epochs = 3\nlosses = train(capsule_net, criterion, optimizer, n_epochs=n_epochs)","execution_count":17,"outputs":[{"output_type":"stream","text":"Epoch: 1 \tTraining Loss: 0.25195038\nEpoch: 1 \tTraining Loss: 0.09796035\nEpoch: 1 \tTraining Loss: 0.07595014\nEpoch: 1 \tTraining Loss: 0.06095914\nEpoch: 1 \tTraining Loss: 0.06084737\nEpoch: 1 \tTraining Loss: 0.05483506\nEpoch: 1 \tTraining Loss: 0.05170787\nEpoch: 1 \tTraining Loss: 0.05093455\nEpoch: 1 \tTraining Loss: 0.04797480\nEpoch: 2 \tTraining Loss: 0.04325662\nEpoch: 2 \tTraining Loss: 0.04132069\nEpoch: 2 \tTraining Loss: 0.03693149\nEpoch: 2 \tTraining Loss: 0.03543177\nEpoch: 2 \tTraining Loss: 0.03564061\nEpoch: 2 \tTraining Loss: 0.03433746\nEpoch: 2 \tTraining Loss: 0.03457587\nEpoch: 2 \tTraining Loss: 0.03337105\nEpoch: 2 \tTraining Loss: 0.03357981\nEpoch: 3 \tTraining Loss: 0.03120700\nEpoch: 3 \tTraining Loss: 0.02949050\nEpoch: 3 \tTraining Loss: 0.02822634\nEpoch: 3 \tTraining Loss: 0.02653409\nEpoch: 3 \tTraining Loss: 0.02738001\nEpoch: 3 \tTraining Loss: 0.02647514\nEpoch: 3 \tTraining Loss: 0.02749124\nEpoch: 3 \tTraining Loss: 0.02626674\nEpoch: 3 \tTraining Loss: 0.02744889\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(losses)\nplt.title(\"Training Loss\")\nplt.show()","execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test(capsule_net, test_loader):\n    \n    \"\"\"\n    Prints out test statistics for a given capsule net.\n    capsule_net: trained capsule network\n    test_loader: test dataloader\n    return: returns last batch of test image data and corresponding reconstructions\n    \"\"\"\n    \n    class_correct = list(0. for i in range(10))\n    class_total = list(0. for i in range(10))\n    \n    test_loss = 0 # loss tracking\n\n    capsule_net.eval() # eval mode\n\n    for batch_i, (images, target) in enumerate(test_loader):\n        \n        target = torch.eye(10).index_select(dim=0, index=target)\n\n        batch_size = images.size(0)\n        \n        images, target = images.to(device), target.to(device)\n\n        # forward pass: compute predicted outputs by passing inputs to the model\n        caps_output, reconstructions, y = capsule_net(images)\n        \n        # calculate the loss\n        loss = criterion(caps_output, target, images, reconstructions)\n        \n        # update average test loss \n        test_loss += loss.item()\n        \n        # convert output probabilities to predicted class\n        _, pred = torch.max(y.data.cpu(), 1)\n        _, target_shape = torch.max(target.data.cpu(), 1)\n\n        # compare predictions to true label\n        correct = np.squeeze(pred.eq(target_shape.data.view_as(pred)))\n        \n        # calculate test accuracy for each object class\n        for i in range(batch_size):\n            \n            label = target_shape.data[i]\n            class_correct[label] += correct[i].item()\n            class_total[label] += 1\n\n    # avg test loss\n    avg_test_loss = test_loss/len(test_loader)\n    \n    print('Test Loss: {:.8f}\\n'.format(avg_test_loss))\n\n    for i in range(10):\n        if class_total[i] > 0:\n            \n            print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (str(i), 100 * class_correct[i] / class_total[i], np.sum(class_correct[i]), np.sum(class_total[i])))\n            \n        else:\n            \n            print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n\n    print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (100. * np.sum(class_correct) / np.sum(class_total), np.sum(class_correct), np.sum(class_total)))\n    \n    # return last batch of capsule vectors, images, reconstructions\n    return caps_output, images, reconstructions","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# call test function and get reconstructed images\ncaps_output, images, reconstructions = test(capsule_net, test_loader)","execution_count":20,"outputs":[{"output_type":"stream","text":"Test Loss: 0.03342544\n\nTest Accuracy of     0: 99% (979/980)\nTest Accuracy of     1: 99% (1132/1135)\nTest Accuracy of     2: 99% (1028/1032)\nTest Accuracy of     3: 98% (996/1010)\nTest Accuracy of     4: 98% (965/982)\nTest Accuracy of     5: 99% (889/892)\nTest Accuracy of     6: 98% (944/958)\nTest Accuracy of     7: 98% (1016/1028)\nTest Accuracy of     8: 98% (962/974)\nTest Accuracy of     9: 97% (987/1009)\n\nTest Accuracy (Overall): 98% (9898/10000)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_images(images, reconstructions):\n    \n    \"\"\"\n    Plot one row of original MNIST images and another row (below) of their reconstructions.\n    \"\"\"\n    \n    # convert to numpy images\n    \n    images = images.data.cpu().numpy()\n    reconstructions = reconstructions.view(-1, 1, 28, 28)\n    reconstructions = reconstructions.data.cpu().numpy()\n    \n    # plot the first ten input images and then reconstructed images\n    \n    fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(26,5))\n\n    # input images on top row, reconstructions on bottom\n    \n    for images, row in zip([images, reconstructions], axes):\n        \n        for img, ax in zip(images, row):\n            \n            ax.imshow(np.squeeze(img), cmap='gray')\n            ax.get_xaxis().set_visible(False)\n            ax.get_yaxis().set_visible(False)","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# display original and reconstructed images, in rows\ndisplay_images(images, reconstructions)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}